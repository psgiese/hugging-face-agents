{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools in LlamaIndex\n",
    "\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "## Let's install the dependencies\n",
    "\n",
    "We will install the dependencies for this unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-index datasets llama-index-callbacks-arize-phoenix llama-index-vector-stores-chroma llama-index-llms-huggingface-api -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, let's log in to Hugging Face to use serverless Inference APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5186b9c6d4d44ba0a1841dc859e026bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a FunctionTool\n",
    "\n",
    "Let's create a basic `FunctionTool` and call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weather for New York\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolOutput(content='The weather in New York is sunny', tool_name='my_weather_tool', raw_input={'args': ('New York',), 'kwargs': {}}, raw_output='The weather in New York is sunny', is_error=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
    "    print(f\"Getting weather for {location}\")\n",
    "    return f\"The weather in {location} is sunny\"\n",
    "\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    name=\"my_weather_tool\",\n",
    "    description=\"Useful for getting the weather for a given location.\",\n",
    ")\n",
    "tool.call(\"New York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a QueryEngineTool\n",
    "\n",
    "Let's now re-use the `QueryEngine` we defined in the [previous unit on tools](/tools.ipynb) and convert it into a `QueryEngineTool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/6bsrztp11777s06bs8q25y2h0000gn/T/ipykernel_95700/3750542470.py:12: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPIEmbedding. (Deprecated in favor of `HuggingFaceInferenceAPIEmbedding` from `llama-index-embeddings-huggingface-api` which should be used instead.)\n",
      "  embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolOutput(content='This individual would likely approach the topic with a nuanced understanding of the complex interplay between technological advancements and societal shifts. Their research would likely delve into the ways in which AI is transforming traditional industries and the resulting impact on employment patterns, social structures, and community development. They might also explore the potential for AI to exacerbate existing social inequalities and the need for policymakers to develop strategies that mitigate these effects.', tool_name='some useful name', raw_input={'input': 'Responds about research on the impact of AI on the future of work and society?'}, raw_output=Response(response='This individual would likely approach the topic with a nuanced understanding of the complex interplay between technological advancements and societal shifts. Their research would likely delve into the ways in which AI is transforming traditional industries and the resulting impact on employment patterns, social structures, and community development. They might also explore the potential for AI to exacerbate existing social inequalities and the need for policymakers to develop strategies that mitigate these effects.', source_nodes=[NodeWithScore(node=TextNode(id_='d7787299-2012-47a0-99ac-2a195d86dbe7', embedding=None, metadata={'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ff53fb44-c6c6-4c4e-8740-12629830b27b', node_type='4', metadata={'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.37195029069907287), NodeWithScore(node=TextNode(id_='4f36820a-6975-4ef4-964e-3240c1dd7d2d', embedding=None, metadata={'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='29d6b293-e7eb-4424-b71f-171ac814748f', node_type='4', metadata={'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, hash='19628b0ae4a0f0ebd63b75e13df7d9183f42e8bb84358fdc2c9049c016c4b67d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental historian or urban planner focused on ecological conservation and sustainability, likely working in local government or a related organization.', mimetype='text/plain', start_char_idx=0, end_char_idx=160, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3697278367716309)], metadata={'d7787299-2012-47a0-99ac-2a195d86dbe7': {'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, '4f36820a-6975-4ef4-964e-3240c1dd7d2d': {'file_path': '/Users/paigegiese/SYG/buildaidaho/agents-course/notebooks/unit2/llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}}), is_error=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceInferenceAPIEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"some useful name\",\n",
    "    description=\"some useful description\",\n",
    ")\n",
    "await tool.acall(\n",
    "    \"Responds about research on the impact of AI on the future of work and society?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Toolspecs\n",
    "\n",
    "Let's create a `ToolSpec` from the `GmailToolSpec` from the LlamaHub and convert it to a list of tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgoogle\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m GmailToolSpec\n\u001b[1;32m      3\u001b[0m tool_spec \u001b[39m=\u001b[39m GmailToolSpec()\n\u001b[1;32m      4\u001b[0m tool_spec_list \u001b[39m=\u001b[39m tool_spec\u001b[39m.\u001b[39mto_tool_list()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.tools'"
     ]
    }
   ],
   "source": [
    "from llama_index.tools.google import GmailToolSpec\n",
    "\n",
    "tool_spec = GmailToolSpec()\n",
    "tool_spec_list = tool_spec.to_tool_list()\n",
    "tool_spec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more detailed view of the tools, we can take a look at the `metadata` of each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('load_data',\n",
       "  \"load_data() -> List[llama_index.core.schema.Document]\\nLoad emails from the user's account.\"),\n",
       " ('search_messages',\n",
       "  \"search_messages(query: str, max_results: Optional[int] = None)\\nSearches email messages given a query string and the maximum number\\n        of results requested by the user\\n           Returns: List of relevant message objects up to the maximum number of results.\\n\\n        Args:\\n            query[str]: The user's query\\n            max_results (Optional[int]): The maximum number of search results\\n            to return.\\n        \"),\n",
       " ('create_draft',\n",
       "  \"create_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None) -> str\\nCreate and insert a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n        \"),\n",
       " ('update_draft',\n",
       "  \"update_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None, draft_id: str = None) -> str\\nUpdate a draft email.\\n           Print the returned draft's message and id.\\n           This function is required to be passed a draft_id that is obtained when creating messages\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n            draft_id (str): the id of the draft to be updated\\n        \"),\n",
       " ('get_draft',\n",
       "  \"get_draft(draft_id: str = None) -> str\\nGet a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n        \"),\n",
       " ('send_draft',\n",
       "  \"send_draft(draft_id: str = None) -> str\\nSends a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n        \")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(tool.metadata.name, tool.metadata.description) for tool in tool_spec_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "56eaeff6d1d2396fba8a1359e5066b7802cd1039122f41bd2bd0871b160a011a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
